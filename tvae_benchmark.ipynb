{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-12T04:34:17.239680Z",
     "start_time": "2025-11-12T04:28:24.521504Z"
    }
   },
   "source": [
    "#Modified to save the distributions instead of just taking means\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance, ks_2samp, entropy\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# ========== CONFIGURATION ==========\n",
    "\n",
    "variables = [\n",
    "    \"heartrate\",\n",
    "    \"activity\",\n",
    "    \"step_count\",\n",
    "    \"activity_duration\"\n",
    "]\n",
    "\n",
    "# ========== HELPER FUNCTIONS ==========\n",
    "\n",
    "\n",
    "def compute_jsd(p, q, bins=50):\n",
    "    \"\"\"Fast Jensen–Shannon divergence for continuous data.\"\"\"\n",
    "    p, q = np.asarray(p, float), np.asarray(q, float)\n",
    "    hist_range = (min(p.min(), q.min()), max(p.max(), q.max()))\n",
    "    # Shared bin edges for fair comparison\n",
    "    edges = np.linspace(hist_range[0], hist_range[1], bins + 1)\n",
    "    p_hist, _ = np.histogram(p, bins=edges, density=True)\n",
    "    q_hist, _ = np.histogram(q, bins=edges, density=True)\n",
    "    p_hist /= p_hist.sum() + 1e-12\n",
    "    q_hist /= q_hist.sum() + 1e-12\n",
    "    m = 0.5 * (p_hist + q_hist)\n",
    "    jsd = 0.5 * (entropy(p_hist, m) + entropy(q_hist, m))\n",
    "    return np.sqrt(jsd)\n",
    "\n",
    "def distance_correlation(x, y):\n",
    "    \"\"\"Approximate distance correlation using rank-based estimator (linear time).\"\"\"\n",
    "    x, y = np.asarray(x, float), np.asarray(y, float)\n",
    "    n = min(len(x), len(y))\n",
    "    if n < 2:\n",
    "        return np.nan\n",
    "    x, y = x[:n], y[:n]\n",
    "    rx = np.argsort(np.argsort(x))\n",
    "    ry = np.argsort(np.argsort(y))\n",
    "    cov_xy = np.cov(rx, ry, bias=True)[0, 1]\n",
    "    stdx = np.std(rx)\n",
    "    stdy = np.std(ry)\n",
    "    return 0.0 if stdx * stdy == 0 else cov_xy / (stdx * stdy)\n",
    "# ========== MAIN COMPARISON FUNCTION ==========\n",
    "#\n",
    "# def compare_data(df1, df2, label=\"comparison\", match_datetimes=False, input_type='real'):\n",
    "#     \"\"\"Compare two DataFrames and return metric dictionary keyed by metric name.\"\"\"\n",
    "#     if any(v not in df1.columns or v not in df2.columns for v in variables):\n",
    "#         raise ValueError(\"Both DataFrames must contain all variables of interest.\")\n",
    "#\n",
    "#     # Handle datetimes\n",
    "#     if 'Datetime' not in df1.columns or 'Datetime' not in df2.columns:\n",
    "#         raise ValueError(\"Both CSVs must contain a 'Datetime' column.\")\n",
    "#     fmt1 = '%Y-%m-%d %H:%M:%S'\n",
    "#     df1['Datetime'] = pd.to_datetime(df1['Datetime'], errors='coerce', format=fmt1)\n",
    "#     fmt2= '%Y-%m-%d %H:%M:%S'\n",
    "#     df2['Datetime'] = pd.to_datetime(df2['Datetime'], errors='coerce', format=fmt2)\n",
    "#     df1, df2 = df1.dropna(subset=['Datetime']), df2.dropna(subset=['Datetime'])\n",
    "#     df1 = df1.drop_duplicates(subset=['Datetime'], keep='first')\n",
    "#     df2 = df2.drop_duplicates(subset=['Datetime'], keep='first')\n",
    "#     # if match_datetimes:\n",
    "#     #     df1 = df1[df1['Datetime'].isin(df2['Datetime'])].reset_index(drop=True)\n",
    "#\n",
    "#     # Initialize results per metric\n",
    "#     metric_results = {\n",
    "#         \"Wasserstein\": {\"Comparison\": label},\n",
    "#         \"KS_statistic\": {\"Comparison\": label},\n",
    "#         \"JSD\": {\"Comparison\": label},\n",
    "#         \"Distance_correlation\": {\"Comparison\": label},\n",
    "#     }\n",
    "#\n",
    "#     # Compute per-variable metrics\n",
    "#     for var in variables:\n",
    "#         # print(f\"Comparing {var}...\")\n",
    "#         x, y = df1[var].dropna(), df2[var].dropna()\n",
    "#         # print(x.shape, y.shape)\n",
    "#         if len(x) == 0 or len(y) == 0:\n",
    "#             for m in metric_results:\n",
    "#                 metric_results[m][var] = np.nan\n",
    "#             continue\n",
    "#\n",
    "#         if var == \"Activity_Type\" or x.dtype == object:\n",
    "#             # Categorical → JSD only\n",
    "#             p = x.value_counts(normalize=True)\n",
    "#             q = y.value_counts(normalize=True)\n",
    "#             common_idx = p.index.union(q.index)\n",
    "#             p = p.reindex(common_idx, fill_value=0)\n",
    "#             q = q.reindex(common_idx, fill_value=0)\n",
    "#             jsd = jensenshannon(p, q)\n",
    "#             metric_results[\"JSD\"][var] = jsd\n",
    "#             for m in [\"Wasserstein\", \"KS_statistic\", \"Distance_correlation\"]:\n",
    "#                 metric_results[m][var] = np.nan\n",
    "#         else:\n",
    "#             # Continuous\n",
    "#             metric_results[\"Wasserstein\"][var] = wasserstein_distance(x, y)\n",
    "#             metric_results[\"KS_statistic\"][var] = ks_2samp(x, y).statistic\n",
    "#             metric_results[\"JSD\"][var] = compute_jsd(x, y)\n",
    "#             metric_results[\"Distance_correlation\"][var] = distance_correlation(x, y)\n",
    "#\n",
    "#     return metric_results\n",
    "def compare_data_fast(df1, df2, variables, label=\"comparison\"):\n",
    "    \"\"\"\n",
    "    Compare two DataFrames of wearable variables using multiple distance metrics.\n",
    "    Much faster than the original implementation.\n",
    "    \"\"\"\n",
    "    # Initialize results\n",
    "    metrics = [\"Wasserstein\", \"KS_statistic\", \"JSD\", \"Distance_correlation\"]\n",
    "    metric_results = {m: {\"Comparison\": label} for m in metrics}\n",
    "\n",
    "    # Ensure valid datetimes and remove duplicates\n",
    "\n",
    "    for var in variables:\n",
    "        if var not in df1.columns or var not in df2.columns:\n",
    "            for m in metrics: metric_results[m][var] = np.nan\n",
    "            continue\n",
    "\n",
    "        x, y = df1[var].dropna(), df2[var].dropna()\n",
    "        if len(x) == 0 or len(y) == 0:\n",
    "            for m in metrics: metric_results[m][var] = np.nan\n",
    "            continue\n",
    "\n",
    "        # Handle categorical variables separately\n",
    "        if var == \"activity\" or x.dtype == object:\n",
    "            p = x.value_counts(normalize=True)\n",
    "            q = y.value_counts(normalize=True)\n",
    "            common = p.index.union(q.index)\n",
    "            p = p.reindex(common, fill_value=0)\n",
    "            q = q.reindex(common, fill_value=0)\n",
    "            metric_results[\"JSD\"][var] = jensenshannon(p, q)\n",
    "            metric_results[\"Wasserstein\"][var] = np.nan\n",
    "            metric_results[\"KS_statistic\"][var] = np.nan\n",
    "            metric_results[\"Distance_correlation\"][var] = np.nan\n",
    "        else:\n",
    "            xv, yv = x.values, y.values\n",
    "            metric_results[\"Wasserstein\"][var] = wasserstein_distance(xv, yv)\n",
    "            metric_results[\"KS_statistic\"][var] = ks_2samp(xv, yv).statistic\n",
    "            metric_results[\"JSD\"][var] = compute_jsd(xv, yv)\n",
    "            metric_results[\"Distance_correlation\"][var] = distance_correlation(xv, yv)\n",
    "\n",
    "    return metric_results\n",
    "\n",
    "# ========== CSV SAVING UTILITY ==========\n",
    "\n",
    "def save_metric_csvs(all_metric_results, output_dir=\"metric_results\"):\n",
    "    \"\"\"\n",
    "    Combine all comparison results and save one CSV per metric.\n",
    "    all_metric_results: list of dicts returned by compare_data()\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    metrics = [\"Wasserstein\", \"KS_statistic\", \"JSD\", \"Distance_correlation\"]\n",
    "\n",
    "    for metric in metrics:\n",
    "        df_metric = pd.DataFrame([r[metric] for r in all_metric_results])\n",
    "        df_metric.to_csv(os.path.join(output_dir, f\"{metric}_results.csv\"), index=False)\n",
    "        print(f\"Saved {metric}_results.csv with {len(df_metric)} comparisons.\")\n",
    "\n",
    "\n",
    "# ========== EXAMPLE USAGE ==========\n",
    "# for warmup in warmup_grid:\n",
    "#     for alpha in alpha_grid:\n",
    "#         print(f\"alpha: {alpha}, warmup: {warmup}\")\n",
    "# synth_dir = f\"sim_alpha_{alpha}_warmup_{warmup}\"\n",
    "synth_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\tvae\\samples_zufferey'\n",
    "print(f\"synth_dir: {synth_dir}\")\n",
    "output_dir = f\"results_final_rev_tvae_zufferey\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "i=0\n",
    "for file1 in glob.glob(os.path.join(synth_dir, '*.csv')):\n",
    "    j=0\n",
    "    synth_df_1 = pd.read_csv(file1)\n",
    "    for file2 in glob.glob(os.path.join(synth_dir, '*.csv')):\n",
    "        if file1 == file2:\n",
    "            continue\n",
    "        synth_df_2 = pd.read_csv(file2)\n",
    "        # synth_df_1['Activity_Type'] = synth_df_1['Activity_Type'].map(activity_state_dict_inverse)\n",
    "        # synth_df_2['Activity_Type'] = synth_df_2['Activity_Type'].map(activity_state_dict_inverse)\n",
    "        results_df = pd.DataFrame(compare_data_fast(synth_df_1, synth_df_2, variables, label=f\"{i}_vs_{i}\"))\n",
    "        results_df.to_csv(os.path.join(output_dir, f\"{i}_vs_{j}.csv\"))\n",
    "        j+=1\n",
    "    i+=1\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# synth_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\sim_alpha_0_warmup_0'\n",
    "# self_comparison_result_list = []\n",
    "# activity_state_dict_inverse = {val:key for key, val in activity_state_dict.items()}\n",
    "# for i in range(len(data)):\n",
    "#     # for j in range(i+1, len(data)):\n",
    "#     #     print(f\"Comparing {i} to {j}\")\n",
    "#     #     df = data[i].copy()\n",
    "#     #     ref_df = data[j].copy()\n",
    "#     #     df['Activity_Type'] = df['Activity_Type'].map(activity_state_dict_inverse)\n",
    "#     #     ref_df['Activity_Type'] = ref_df['Activity_Type'].map(activity_state_dict_inverse)\n",
    "#     #     results_df = pd.DataFrame(compare_data(df, ref_df, label=f\"{i}_vs_{j}\", input_type='real'))\n",
    "#     #     results_df.to_csv(os.path.join(output_dir, f\"{i}_vs_{j}.csv\"))\n",
    "#     #     self_comparison_result_list.append(results_df)\n",
    "#     j = 0\n",
    "#     for file in glob.glob(os.path.join(synth_dir, '*.csv')):\n",
    "#         print(f'Comparing {i} to {j}')\n",
    "#         ref_df = data[i].copy()\n",
    "#         synth_df = pd.read_csv(file)\n",
    "#         synth_df['Activity_Type'] = synth_df['Activity_Type'].map(activity_state_dict_inverse)\n",
    "#         ref_df['Activity_Type'] = ref_df['Activity_Type'].map(activity_state_dict_inverse)\n",
    "#         results_df = pd.DataFrame(compare_data(synth_df, ref_df, label=f\"{i}_vs_{j}\", match_datetimes = True, input_type='synth'))\n",
    "#         # print(results_df)\n",
    "#         results_df.to_csv(os.path.join(output_dir, f\"{i}_vs_{j}.csv\"))\n",
    "#         j+=1\n",
    "#\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synth_dir: C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\tvae\\samples_zufferey\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T04:38:37.529236Z",
     "start_time": "2025-11-12T04:38:32.878484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========= CONFIGURATION =========\n",
    "reference_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\reference_results'\n",
    "evaluation_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\results_final_rev_tvae'\n",
    "n_boot = 1000\n",
    "output_csv = 'tvae_bootstrap_summary_bhi_final.csv'\n",
    "\n",
    "# ========= HELPER FUNCTIONS =========\n",
    "\n",
    "def load_metric_csv(path):\n",
    "    \"\"\"Load a metric CSV and drop non-numeric rows.\"\"\"\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df.dropna(how='all')  # remove empty rows\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def summarize_bootstrap(diffs):\n",
    "    \"\"\"Compute summary statistics from a 3D array (bootstraps × vars × metrics).\"\"\"\n",
    "    summary = {}\n",
    "    for metric in diffs.columns:\n",
    "        data = diffs[metric].dropna()\n",
    "        summary[metric] = {\n",
    "            'mean': data.mean(),\n",
    "            'std': data.std(),\n",
    "            'median': data.median(),\n",
    "            'IQR': data.quantile(0.75) - data.quantile(0.25),\n",
    "            'range': data.max() - data.min(),\n",
    "            '95%_CI_low': np.percentile(data, 2.5),\n",
    "            '95%_CI_high': np.percentile(data, 97.5)\n",
    "        }\n",
    "    return pd.DataFrame(summary).T\n",
    "\n",
    "# ========= LOAD FILES =========\n",
    "\n",
    "ref_files = sorted([os.path.join(reference_dir, f) for f in os.listdir(reference_dir) if f.endswith('.csv')])\n",
    "eval_files = sorted([os.path.join(evaluation_dir, f) for f in os.listdir(evaluation_dir) if f.endswith('.csv')])\n",
    "\n",
    "if len(ref_files) == 0 or len(eval_files) == 0:\n",
    "    raise ValueError(\"No CSV files found in one or both folders.\")\n",
    "\n",
    "# ========= BOOTSTRAP =========\n",
    "\n",
    "abs_boot = []  # list of DataFrames (abs differences)\n",
    "rel_boot = []  # list of DataFrames (rel differences)\n",
    "\n",
    "for _ in tqdm(range(n_boot), desc=\"Bootstrapping\"):\n",
    "    ref_path = np.random.choice(ref_files)\n",
    "    eval_path = np.random.choice(eval_files)\n",
    "\n",
    "    ref_df = load_metric_csv(ref_path)\n",
    "    eval_df = load_metric_csv(eval_path)\n",
    "\n",
    "    # Ensure same indices and columns\n",
    "    common_rows = ref_df.index.intersection(eval_df.index)\n",
    "    common_cols = ref_df.columns.intersection(eval_df.columns)\n",
    "    ref_df = ref_df.loc[common_rows, common_cols]\n",
    "    eval_df = eval_df.loc[common_rows, common_cols]\n",
    "\n",
    "    abs_diff = (eval_df - ref_df).abs()\n",
    "    rel_diff = abs_diff / ref_df.replace(0, np.nan).abs()  # avoid divide-by-zero\n",
    "\n",
    "    abs_boot.append(abs_diff)\n",
    "    rel_boot.append(rel_diff)\n",
    "\n",
    "print(abs_boot[0])\n",
    "print(rel_boot[0])\n",
    "# ========= AGGREGATE RESULTS =========\n",
    "\n",
    "abs_concat = pd.concat(abs_boot, axis=0, ignore_index=True)\n",
    "rel_concat = pd.concat(rel_boot, axis=0, ignore_index=True)\n",
    "abs_summary = summarize_bootstrap(abs_concat)\n",
    "rel_summary = summarize_bootstrap(rel_concat)\n",
    "\n",
    "# Combine and label\n",
    "abs_summary['Type'] = 'Absolute'\n",
    "rel_summary['Type'] = 'Relative'\n",
    "summary = pd.concat([abs_summary, rel_summary])\n",
    "\n",
    "# ========= SAVE =========\n",
    "summary.to_csv(output_csv, index_label='Metric')\n",
    "print(f\"Bootstrap summary saved to {output_csv}\")\n",
    "\n",
    "# ========= OPTIONAL: Display =========\n",
    "print(summary)\n"
   ],
   "id": "b9d5854503325462",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [00:04<00:00, 218.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Wasserstein  KS_statistic       JSD  \\\n",
      "Comparison                           NaN           NaN       NaN   \n",
      "Activity_Type                        NaN           NaN  0.149942   \n",
      "Heart rate___beats/minute       9.764735      0.165744  0.281103   \n",
      "Calories burned_kcal           11.016143      0.146368  0.328946   \n",
      "Exercise duration_s           116.559992      0.170834  0.383361   \n",
      "Sleep duration_minutes          4.605763      0.180928  0.261634   \n",
      "Sleep type duration_minutes     2.943984      0.215605  0.280553   \n",
      "Floors climbed___floors         0.000000      0.000000       NaN   \n",
      "\n",
      "                             Distance_correlation  \n",
      "Comparison                                    NaN  \n",
      "Activity_Type                                 NaN  \n",
      "Heart rate___beats/minute                0.034765  \n",
      "Calories burned_kcal                     0.076991  \n",
      "Exercise duration_s                      0.164178  \n",
      "Sleep duration_minutes                   0.111097  \n",
      "Sleep type duration_minutes              0.092024  \n",
      "Floors climbed___floors                  1.000000  \n",
      "                             Wasserstein  KS_statistic       JSD  \\\n",
      "Comparison                           NaN           NaN       NaN   \n",
      "Activity_Type                        NaN           NaN  0.957822   \n",
      "Heart rate___beats/minute       0.973939      0.962074  0.917070   \n",
      "Calories burned_kcal            0.948399      0.935637  0.878426   \n",
      "Exercise duration_s             0.931693      0.869365  0.870808   \n",
      "Sleep duration_minutes          0.978116      0.952377  0.860905   \n",
      "Sleep type duration_minutes     0.984132      0.978469  0.915654   \n",
      "Floors climbed___floors              NaN           NaN       NaN   \n",
      "\n",
      "                             Distance_correlation  \n",
      "Comparison                                    NaN  \n",
      "Activity_Type                                 NaN  \n",
      "Heart rate___beats/minute                0.210111  \n",
      "Calories burned_kcal                     0.256351  \n",
      "Exercise duration_s                      0.730446  \n",
      "Sleep duration_minutes                   0.699680  \n",
      "Sleep type duration_minutes              0.583064  \n",
      "Floors climbed___floors                       NaN  \n",
      "Bootstrap summary saved to tvae_bootstrap_summary_bhi_final.csv\n",
      "                           mean        std    median        IQR       range  \\\n",
      "Wasserstein           19.225684  40.771213  3.137269  13.131006  392.930932   \n",
      "KS_statistic           0.126515   0.102369  0.109955   0.111263    0.754097   \n",
      "JSD                    0.244783   0.097746  0.247368   0.131380    0.588501   \n",
      "Distance_correlation   0.254942   0.343682  0.100010   0.211681    0.999973   \n",
      "Wasserstein            0.930887   0.059186  0.947973   0.056384    0.617493   \n",
      "KS_statistic           0.918026   0.054318  0.932073   0.060877    0.580951   \n",
      "JSD                    0.878676   0.041431  0.880051   0.047779    0.544570   \n",
      "Distance_correlation   0.563412   0.609245  0.392895   0.565618    5.554319   \n",
      "\n",
      "                      95%_CI_low  95%_CI_high      Type  \n",
      "Wasserstein             0.000000   146.928471  Absolute  \n",
      "KS_statistic            0.000000     0.384915  Absolute  \n",
      "JSD                     0.051186     0.426322  Absolute  \n",
      "Distance_correlation    0.004477     1.000000  Absolute  \n",
      "Wasserstein             0.767897     0.988108  Relative  \n",
      "KS_statistic            0.777160     0.981380  Relative  \n",
      "JSD                     0.796951     0.956147  Relative  \n",
      "Distance_correlation    0.018297     2.457802  Relative  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-17T17:54:45.646864Z",
     "start_time": "2025-11-17T17:53:14.218145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# ========= CONFIGURATION =========\n",
    "reference_dir = (r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\ctgan\\reference\\comparison_summary_zufferey')\n",
    "evaluation_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\ctgan\\results_final_rev_ctgan_zufferey'\n",
    "n_boot = 1000\n",
    "n_sample = 1000  # number of CSVs sampled per bootstrap\n",
    "output_csv = 'ctgan_bootstrap_WD_summary_fitbit.csv'\n",
    "\n",
    "metric_files = [\n",
    "    \"Wasserstein_results.csv\",\n",
    "    \"JSD_results.csv\",\n",
    "    \"KS_results.csv\",\n",
    "    \"DistCorr_results.csv\"\n",
    "]\n",
    "\n",
    "# ========= HELPER FUNCTIONS =========\n",
    "def load_metric_csv(path):\n",
    "    \"\"\"Load a metric CSV and drop non-numeric rows.\"\"\"\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df.dropna(how='all')\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "def summarize_bootstrap(df):\n",
    "    \"\"\"Compute summary stats for WD/JSD results.\"\"\"\n",
    "    summary = (\n",
    "        df.groupby(['Variable', 'Metric'])\n",
    "          .agg(['mean', 'std', 'median',\n",
    "                lambda x: x.quantile(0.25),\n",
    "                lambda x: x.quantile(0.75),\n",
    "                np.min,\n",
    "                np.max,  # range\n",
    "                lambda x: np.percentile(x, 2.5),  # 95% CI low\n",
    "                lambda x: np.percentile(x, 97.5)])  # 95% CI high\n",
    "    )\n",
    "    summary.columns = ['mean', 'std', 'median','IQR_25', 'IQR_75', 'min', 'max', '95%_CI_low', '95%_CI_high']\n",
    "    return summary.reset_index()\n",
    "\n",
    "def compute_jsd(p, q, bins=50):\n",
    "    \"\"\"Compute Jensen–Shannon distance between continuous samples.\"\"\"\n",
    "    if len(p) == 0 or len(q) == 0:\n",
    "        return np.nan\n",
    "    min_v = min(np.min(p), np.min(q))\n",
    "    max_v = max(np.max(p), np.max(q))\n",
    "    if not np.isfinite(min_v) or not np.isfinite(max_v) or min_v == max_v:\n",
    "        return np.nan\n",
    "    hist_p, _ = np.histogram(p, bins=bins, range=(min_v, max_v), density=True)\n",
    "    hist_q, _ = np.histogram(q, bins=bins, range=(min_v, max_v), density=True)\n",
    "    hist_p += 1e-12\n",
    "    hist_q += 1e-12\n",
    "    hist_p /= hist_p.sum()\n",
    "    hist_q /= hist_q.sum()\n",
    "    return jensenshannon(hist_p, hist_q)\n",
    "\n",
    "# ========= LOAD REFERENCE METRIC FILES =========\n",
    "ref_metrics = {}\n",
    "for mfile in metric_files:\n",
    "    metric_name = mfile.split(\"_\")[0]  # e.g., \"Wasserstein\" from \"Wasserstein_results.csv\"\n",
    "    path = os.path.join(reference_dir, mfile)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Reference file not found: {path}\")\n",
    "    if metric_name == 'DistCorr':\n",
    "        metric_name = 'Distance_correlation'\n",
    "    if metric_name == 'KS':\n",
    "        metric_name = 'KS_statistic'\n",
    "    ref_metrics[metric_name] = load_metric_csv(path)\n",
    "\n",
    "print(f\"Loaded reference metrics: {list(ref_metrics.keys())}\")\n",
    "\n",
    "# ========= LOAD EVALUATION FILES =========\n",
    "eval_files = [\n",
    "    load_metric_csv(os.path.join(evaluation_dir, f))\n",
    "    for f in os.listdir(evaluation_dir)\n",
    "    if f.endswith('.csv') and '_vs_' in f\n",
    "]\n",
    "\n",
    "if len(eval_files) == 0:\n",
    "    raise ValueError(\"No evaluation {i}_vs_{j}.csv files found in the directory.\")\n",
    "\n",
    "# ========= DETERMINE COMMON VARIABLES =========\n",
    "common_vars = list(set.intersection(*[set(df.columns) for df in ref_metrics.values()]))\n",
    "print(f\"Found {len(common_vars)} variables shared across all reference metrics.\")\n",
    "\n",
    "# ========= BOOTSTRAP COMPARISON =========\n",
    "records = []\n",
    "\n",
    "for i in tqdm(range(n_boot), desc=\"Bootstrapping WD/JSD\"):\n",
    "    eval_sample_idxs = np.random.choice(len(eval_files), size=n_sample, replace=True)\n",
    "\n",
    "    for metric_name, ref_df in ref_metrics.items():\n",
    "        ref_vals_all = ref_df[common_vars]\n",
    "        ref_vals_all = ref_vals_all.select_dtypes(include=[np.number])\n",
    "\n",
    "        for var in common_vars:\n",
    "            ref_vals = ref_vals_all[var].dropna().values\n",
    "            if len(ref_vals) < 2:\n",
    "                continue\n",
    "\n",
    "            # Gather corresponding metric column from sampled eval files\n",
    "            eval_vals = []\n",
    "            for idx in eval_sample_idxs:\n",
    "                try:\n",
    "                    eval_df = eval_files[idx]\n",
    "                    if metric_name in eval_df.columns and var in eval_df.index:\n",
    "                        val = eval_df.at[var, metric_name]\n",
    "                        if np.isfinite(val):\n",
    "                            eval_vals.append(val)\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if len(eval_vals) < 2:\n",
    "                continue\n",
    "\n",
    "            eval_vals = np.array(eval_vals, dtype=float)\n",
    "            ref_vals = np.array(ref_vals, dtype=float)\n",
    "\n",
    "            # Compute WD and JSD between the bootstrap-sampled distributions\n",
    "            wd = wasserstein_distance(ref_vals, eval_vals)\n",
    "            jsd = compute_jsd(ref_vals, eval_vals)\n",
    "\n",
    "            records.append({\n",
    "                \"Variable\": var,\n",
    "                \"Metric\": metric_name,\n",
    "                \"Wasserstein\": wd\n",
    "                # \"JSD\": jsd\n",
    "            })\n",
    "\n",
    "# ========= SUMMARIZE =========\n",
    "df_results = pd.DataFrame(records)\n",
    "\n",
    "summary_wd = summarize_bootstrap(\n",
    "    df_results[['Variable', 'Metric', 'Wasserstein']].rename(columns={'Wasserstein': 'Value'})\n",
    ")\n",
    "# summary_jsd = summarize_bootstrap(\n",
    "#     df_results[['Variable', 'Metric', 'JSD']].rename(columns={'JSD': 'Value'})\n",
    "# )\n",
    "\n",
    "summary_wd['Distance'] = 'Wasserstein'\n",
    "# summary_jsd['Distance'] = 'JSD'\n",
    "\n",
    "summary = summary_wd\n",
    "# summary = pd.concat([summary_wd, summary_jsd], ignore_index=True)\n",
    "summary = summary[['Variable', 'Metric', 'Distance','mean', 'std', 'median','IQR_25', 'IQR_75', 'min', 'max', '95%_CI_low', '95%_CI_high']]\n",
    "\n",
    "\n",
    "# ========= SAVE =========\n",
    "summary.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✅ Bootstrap WD/JSD summary saved to {output_csv}\")\n",
    "print(summary.head(15))"
   ],
   "id": "e2a681c360291820",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reference metrics: ['Wasserstein', 'JSD', 'KS_statistic', 'Distance_correlation']\n",
      "Found 4 variables shared across all reference metrics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping WD/JSD: 100%|██████████| 1000/1000 [01:18<00:00, 12.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Bootstrap WD/JSD summary saved to ctgan_bootstrap_WD_summary_fitbit.csv\n",
      "             Variable                Metric     Distance       mean       std  \\\n",
      "0            activity                   JSD  Wasserstein   0.505340  0.000080   \n",
      "1   activity_duration  Distance_correlation  Wasserstein   0.182815  0.000224   \n",
      "2   activity_duration                   JSD  Wasserstein   0.471111  0.000079   \n",
      "3   activity_duration          KS_statistic  Wasserstein   0.263113  0.000077   \n",
      "4   activity_duration           Wasserstein  Wasserstein  14.575900  0.004048   \n",
      "5           heartrate  Distance_correlation  Wasserstein   0.230525  0.000230   \n",
      "6           heartrate                   JSD  Wasserstein   0.472832  0.000080   \n",
      "7           heartrate          KS_statistic  Wasserstein   0.325289  0.000072   \n",
      "8           heartrate           Wasserstein  Wasserstein   8.683148  0.002313   \n",
      "9          step_count  Distance_correlation  Wasserstein   0.214065  0.000232   \n",
      "10         step_count                   JSD  Wasserstein   0.501522  0.000074   \n",
      "11         step_count          KS_statistic  Wasserstein   0.292289  0.000066   \n",
      "12         step_count           Wasserstein  Wasserstein  17.299299  0.004752   \n",
      "\n",
      "       median     IQR_25     IQR_75        min        max  95%_CI_low  \\\n",
      "0    0.505339   0.505287   0.505397   0.505075   0.505586    0.505190   \n",
      "1    0.182819   0.182657   0.182967   0.182190   0.183566    0.182382   \n",
      "2    0.471112   0.471061   0.471167   0.470845   0.471355    0.470949   \n",
      "3    0.263110   0.263060   0.263166   0.262831   0.263352    0.262969   \n",
      "4   14.575989  14.572990  14.578714  14.562054  14.588278   14.568024   \n",
      "5    0.230519   0.230363   0.230676   0.229850   0.231244    0.230078   \n",
      "6    0.472834   0.472777   0.472886   0.472561   0.473150    0.472674   \n",
      "7    0.325289   0.325240   0.325338   0.325079   0.325542    0.325154   \n",
      "8    8.683111   8.681592   8.684680   8.676982   8.690681    8.678582   \n",
      "9    0.214077   0.213911   0.214221   0.213384   0.214899    0.213613   \n",
      "10   0.501522   0.501472   0.501569   0.501304   0.501742    0.501388   \n",
      "11   0.292291   0.292249   0.292332   0.292084   0.292494    0.292160   \n",
      "12  17.299385  17.296181  17.302430  17.284679  17.314885   17.290206   \n",
      "\n",
      "    95%_CI_high  \n",
      "0      0.505493  \n",
      "1      0.183233  \n",
      "2      0.471259  \n",
      "3      0.263261  \n",
      "4     14.583603  \n",
      "5      0.230970  \n",
      "6      0.472986  \n",
      "7      0.325437  \n",
      "8      8.687902  \n",
      "9      0.214506  \n",
      "10     0.501673  \n",
      "11     0.292417  \n",
      "12    17.308432  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Darren\\AppData\\Local\\Temp\\ipykernel_3148\\2131998029.py:34: FutureWarning: The provided callable <function min at 0x000001BF78D72C20> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  .agg(['mean', 'std', 'median',\n",
      "C:\\Users\\Darren\\AppData\\Local\\Temp\\ipykernel_3148\\2131998029.py:34: FutureWarning: The provided callable <function max at 0x000001BF78D72B00> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  .agg(['mean', 'std', 'median',\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common variables: ['Floors climbed___floors', 'Heart rate___beats/minute', 'Sleep type duration_minutes', 'Activity_Type', 'Calories burned_kcal', 'Comparison', 'Exercise duration_s', 'Sleep duration_minutes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bootstrapping: 100%|██████████| 1000/1000 [04:21<00:00,  3.83it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1943\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1942\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1943\u001B[0m     res_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_grouper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43mser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1944\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001B[0m, in \u001B[0;36mBaseGrouper.agg_series\u001B[1;34m(self, obj, func, preserve_dtype)\u001B[0m\n\u001B[0;32m    862\u001B[0m     preserve_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 864\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_aggregate_series_pure_python\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    866\u001B[0m npvalues \u001B[38;5;241m=\u001B[39m lib\u001B[38;5;241m.\u001B[39mmaybe_convert_objects(result, try_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001B[0m, in \u001B[0;36mBaseGrouper._aggregate_series_pure_python\u001B[1;34m(self, obj, func)\u001B[0m\n\u001B[0;32m    884\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(splitter):\n\u001B[1;32m--> 885\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgroup\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    886\u001B[0m     res \u001B[38;5;241m=\u001B[39m extract_result(res)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2460\u001B[0m, in \u001B[0;36mGroupBy.mean.<locals>.<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   2457\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2458\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cython_agg_general(\n\u001B[0;32m   2459\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m-> 2460\u001B[0m         alt\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   2461\u001B[0m         numeric_only\u001B[38;5;241m=\u001B[39mnumeric_only,\n\u001B[0;32m   2462\u001B[0m     )\n\u001B[0;32m   2463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgroupby\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\series.py:6560\u001B[0m, in \u001B[0;36mSeries.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6552\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m   6554\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6558\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6559\u001B[0m ):\n\u001B[1;32m-> 6560\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m NDFrame\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28mself\u001B[39m, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\generic.py:12439\u001B[0m, in \u001B[0;36mNDFrame.mean\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12432\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mmean\u001B[39m(\n\u001B[0;32m  12433\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12434\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12437\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12438\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[1;32m> 12439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stat_function(\n\u001B[0;32m  12440\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m, nanops\u001B[38;5;241m.\u001B[39mnanmean, axis, skipna, numeric_only, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m  12441\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\generic.py:12396\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12394\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12396\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  12397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\n\u001B[0;32m  12398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\series.py:6468\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6464\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6465\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6466\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6467\u001B[0m     )\n\u001B[1;32m-> 6468\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op(delegate, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m func(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, mask\u001B[38;5;241m=\u001B[39mmask, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\nanops.py:720\u001B[0m, in \u001B[0;36mnanmean\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m    719\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39msum(axis, dtype\u001B[38;5;241m=\u001B[39mdtype_sum)\n\u001B[1;32m--> 720\u001B[0m the_sum \u001B[38;5;241m=\u001B[39m \u001B[43m_ensure_numeric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthe_sum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    722\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(the_sum, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\nanops.py:1701\u001B[0m, in \u001B[0;36m_ensure_numeric\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1700\u001B[0m     \u001B[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001B[39;00m\n\u001B[1;32m-> 1701\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not convert string \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to numeric\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1702\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[1;31mTypeError\u001B[0m: Could not convert string 'WassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWassersteinWasserstein' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 128\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;66;03m# ========= SUMMARY OUTPUT =========\u001B[39;00m\n\u001B[0;32m    126\u001B[0m df_results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(records)\n\u001B[1;32m--> 128\u001B[0m summary \u001B[38;5;241m=\u001B[39m \u001B[43msummarize_bootstrap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_results\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    129\u001B[0m summary \u001B[38;5;241m=\u001B[39m summary[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVariable\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMetric\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    130\u001B[0m                    \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIQR_25\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIQR_75\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m95\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m_CI_low\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m95\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m_CI_high\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m    131\u001B[0m summary[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDistance\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWasserstein\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "Cell \u001B[1;32mIn[2], line 47\u001B[0m, in \u001B[0;36msummarize_bootstrap\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msummarize_bootstrap\u001B[39m(df):\n\u001B[0;32m     45\u001B[0m     summary \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     46\u001B[0m         \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mVariable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMetric\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m---> 47\u001B[0m \u001B[43m          \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstd\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmedian\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.25\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantile\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.75\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m                \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m                \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpercentile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpercentile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m97.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     )\n\u001B[0;32m     55\u001B[0m     summary\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstd\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmedian\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIQR_25\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIQR_75\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     56\u001B[0m                        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m95\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m_CI_low\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m95\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m_CI_high\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m summary\u001B[38;5;241m.\u001B[39mreset_index()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001B[0m, in \u001B[0;36mDataFrameGroupBy.aggregate\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1429\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m engine_kwargs\n\u001B[0;32m   1431\u001B[0m op \u001B[38;5;241m=\u001B[39m GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m-> 1432\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1433\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1434\u001B[0m     \u001B[38;5;66;03m# GH #52849\u001B[39;00m\n\u001B[0;32m   1435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mas_index \u001B[38;5;129;01mand\u001B[39;00m is_list_like(func):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\apply.py:193\u001B[0m, in \u001B[0;36mApply.agg\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magg_dict_like()\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(func):\n\u001B[0;32m    192\u001B[0m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[1;32m--> 193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_list_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(func):\n\u001B[0;32m    196\u001B[0m     f \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mget_cython_func(func)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\apply.py:326\u001B[0m, in \u001B[0;36mApply.agg_list_like\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21magg_list_like\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m    319\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    320\u001B[0m \u001B[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001B[39;00m\n\u001B[0;32m    321\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;124;03m    Result of aggregation.\u001B[39;00m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_or_apply_list_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43magg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\apply.py:1566\u001B[0m, in \u001B[0;36mGroupByApply.agg_or_apply_list_like\u001B[1;34m(self, op_name)\u001B[0m\n\u001B[0;32m   1561\u001B[0m \u001B[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001B[39;00m\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;66;03m# that inherit from this class.\u001B[39;00m\n\u001B[0;32m   1563\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m com\u001B[38;5;241m.\u001B[39mtemp_setattr(\n\u001B[0;32m   1564\u001B[0m     obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas_index\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m, condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mhasattr\u001B[39m(obj, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1565\u001B[0m ):\n\u001B[1;32m-> 1566\u001B[0m     keys, results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_list_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1567\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results_list_like(keys, results)\n\u001B[0;32m   1568\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\apply.py:385\u001B[0m, in \u001B[0;36mApply.compute_list_like\u001B[1;34m(self, op_name, selected_obj, kwargs)\u001B[0m\n\u001B[0;32m    379\u001B[0m colg \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_gotitem(col, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, subset\u001B[38;5;241m=\u001B[39mselected_obj\u001B[38;5;241m.\u001B[39miloc[:, index])\n\u001B[0;32m    380\u001B[0m args \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    381\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs]\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m include_axis(op_name, colg)\n\u001B[0;32m    383\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\n\u001B[0;32m    384\u001B[0m )\n\u001B[1;32m--> 385\u001B[0m new_res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(colg, op_name)(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    386\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(new_res)\n\u001B[0;32m    387\u001B[0m indices\u001B[38;5;241m.\u001B[39mappend(index)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:257\u001B[0m, in \u001B[0;36mSeriesGroupBy.aggregate\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    255\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m engine\n\u001B[0;32m    256\u001B[0m kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m engine_kwargs\n\u001B[1;32m--> 257\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_multiple_funcs(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m relabeling:\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# for mypy\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:362\u001B[0m, in \u001B[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001B[1;34m(self, arg, *args, **kwargs)\u001B[0m\n\u001B[0;32m    360\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx, (name, func) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(arg):\n\u001B[0;32m    361\u001B[0m         key \u001B[38;5;241m=\u001B[39m base\u001B[38;5;241m.\u001B[39mOutputKey(label\u001B[38;5;241m=\u001B[39mname, position\u001B[38;5;241m=\u001B[39midx)\n\u001B[1;32m--> 362\u001B[0m         results[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate(func, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    364\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, DataFrame) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m results\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    365\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m concat\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:249\u001B[0m, in \u001B[0;36mSeriesGroupBy.aggregate\u001B[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m engine_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    248\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mengine_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m engine_kwargs\n\u001B[1;32m--> 249\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, func)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func, abc\u001B[38;5;241m.\u001B[39mIterable):\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;66;03m# Catch instances of lists / tuples\u001B[39;00m\n\u001B[0;32m    253\u001B[0m     \u001B[38;5;66;03m# but not the class list / tuple itself.\u001B[39;00m\n\u001B[0;32m    254\u001B[0m     func \u001B[38;5;241m=\u001B[39m maybe_mangle_lambdas(func)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2458\u001B[0m, in \u001B[0;36mGroupBy.mean\u001B[1;34m(self, numeric_only, engine, engine_kwargs)\u001B[0m\n\u001B[0;32m   2451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_numba_agg_general(\n\u001B[0;32m   2452\u001B[0m         grouped_mean,\n\u001B[0;32m   2453\u001B[0m         executor\u001B[38;5;241m.\u001B[39mfloat_dtype_mapping,\n\u001B[0;32m   2454\u001B[0m         engine_kwargs,\n\u001B[0;32m   2455\u001B[0m         min_periods\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m   2456\u001B[0m     )\n\u001B[0;32m   2457\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2458\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cython_agg_general\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2459\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2460\u001B[0m \u001B[43m        \u001B[49m\u001B[43malt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2462\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgroupby\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2004\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general\u001B[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001B[0m\n\u001B[0;32m   2001\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_agg_py_fallback(how, values, ndim\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, alt\u001B[38;5;241m=\u001B[39malt)\n\u001B[0;32m   2002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[1;32m-> 2004\u001B[0m new_mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrouped_reduce\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2005\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_agged_manager(new_mgr)\n\u001B[0;32m   2006\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m how \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midxmax\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\internals\\base.py:367\u001B[0m, in \u001B[0;36mSingleDataManager.grouped_reduce\u001B[1;34m(self, func)\u001B[0m\n\u001B[0;32m    365\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgrouped_reduce\u001B[39m(\u001B[38;5;28mself\u001B[39m, func):\n\u001B[0;32m    366\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39marray\n\u001B[1;32m--> 367\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    368\u001B[0m     index \u001B[38;5;241m=\u001B[39m default_index(\u001B[38;5;28mlen\u001B[39m(res))\n\u001B[0;32m    370\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_array(res, index)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2001\u001B[0m, in \u001B[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001B[1;34m(values)\u001B[0m\n\u001B[0;32m   1998\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m   2000\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m alt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 2001\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_agg_py_fallback\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhow\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\segpenis\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1947\u001B[0m, in \u001B[0;36mGroupBy._agg_py_fallback\u001B[1;34m(self, how, values, ndim, alt)\u001B[0m\n\u001B[0;32m   1945\u001B[0m     msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magg function failed [how->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhow\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,dtype->\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mser\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1946\u001B[0m     \u001B[38;5;66;03m# preserve the kind of exception that raised\u001B[39;00m\n\u001B[1;32m-> 1947\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(err)(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m dtype \u001B[38;5;241m=\u001B[39m ser\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n",
      "\u001B[1;31mTypeError\u001B[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# ========= CONFIGURATION =========\n",
    "reference_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\reference_results'\n",
    "evaluation_dir = r'C:\\Users\\Darren\\Documents\\BHI and Written Qualifier\\results_final_rev_tvae'\n",
    "\n",
    "n_boot = 1000\n",
    "n_sample = 1000\n",
    "output_csv = 'tvae_bootstrap_WD_summary_final_bhi.csv'\n",
    "\n",
    "METRICS = [\"Wasserstein\", \"KS_statistic\", \"JSD\", \"Distance_correlation\"]\n",
    "\n",
    "\n",
    "# ========= HELPER FUNCTIONS =========\n",
    "def load_vs_csv(path):\n",
    "    \"\"\"Load file with index=variables and metric columns.\"\"\"\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    df = df.apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_jsd(p, q, bins=50):\n",
    "    if len(p) == 0 or len(q) == 0:\n",
    "        return np.nan\n",
    "    low = min(np.min(p), np.min(q))\n",
    "    high = max(np.max(p), np.max(q))\n",
    "    if not np.isfinite(low) or not np.isfinite(high) or low == high:\n",
    "        return np.nan\n",
    "\n",
    "    hist_p, _ = np.histogram(p, bins=bins, range=(low, high), density=True)\n",
    "    hist_q, _ = np.histogram(q, bins=bins, range=(low, high), density=True)\n",
    "    hist_p = np.maximum(hist_p, 1e-12)\n",
    "    hist_q = np.maximum(hist_q, 1e-12)\n",
    "    hist_p /= hist_p.sum()\n",
    "    hist_q /= hist_q.sum()\n",
    "    return jensenshannon(hist_p, hist_q)\n",
    "\n",
    "\n",
    "def summarize_bootstrap(df):\n",
    "    summary = (\n",
    "        df.groupby(['Variable', 'Metric'])\n",
    "          .agg(['mean', 'std', 'median',\n",
    "                lambda x: x.quantile(0.25),\n",
    "                lambda x: x.quantile(0.75),\n",
    "                np.min,\n",
    "                np.max,\n",
    "                lambda x: np.percentile(x, 2.5),\n",
    "                lambda x: np.percentile(x, 97.5)])\n",
    "    )\n",
    "    summary.columns = ['mean', 'std', 'median', 'IQR_25', 'IQR_75',\n",
    "                       'min', 'max', '95%_CI_low', '95%_CI_high']\n",
    "    return summary.reset_index()\n",
    "\n",
    "\n",
    "# ========= LOAD REFERENCE & EVAL FILES =========\n",
    "def load_directory_vs_files(folder):\n",
    "    return [\n",
    "        load_vs_csv(os.path.join(folder, f))\n",
    "        for f in os.listdir(folder)\n",
    "        if f.endswith('.csv') and '_vs_' in f\n",
    "    ]\n",
    "\n",
    "ref_files = load_directory_vs_files(reference_dir)\n",
    "eval_files = load_directory_vs_files(evaluation_dir)\n",
    "\n",
    "if len(ref_files) == 0:\n",
    "    raise ValueError(\"No reference *_vs_*.csv files found.\")\n",
    "if len(eval_files) == 0:\n",
    "    raise ValueError(\"No evaluation *_vs_*.csv files found.\")\n",
    "\n",
    "# ========= Determine common variables across all CSVs =========\n",
    "common_vars = list(\n",
    "    set.intersection(*[set(df.index) for df in ref_files])\n",
    ")\n",
    "print(f\"Common variables: {common_vars}\")\n",
    "\n",
    "# ========= BOOTSTRAP =========\n",
    "records = []\n",
    "\n",
    "for b in tqdm(range(n_boot), desc=\"Bootstrapping\"):\n",
    "    ref_idx = np.random.choice(len(ref_files), size=n_sample, replace=True)\n",
    "    eval_idx = np.random.choice(len(eval_files), size=n_sample, replace=True)\n",
    "\n",
    "    for metric_name in METRICS:\n",
    "        for var in common_vars:\n",
    "\n",
    "            # Collect bootstrap samples\n",
    "            ref_vals = []\n",
    "            for i in ref_idx:\n",
    "                try:\n",
    "                    v = ref_files[i].at[var, metric_name]\n",
    "                    if np.isfinite(v): ref_vals.append(v)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            eval_vals = []\n",
    "            for j in eval_idx:\n",
    "                try:\n",
    "                    v = eval_files[j].at[var, metric_name]\n",
    "                    if np.isfinite(v): eval_vals.append(v)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            if len(ref_vals) < 2 or len(eval_vals) < 2:\n",
    "                continue\n",
    "\n",
    "            ref_vals = np.array(ref_vals, float)\n",
    "            eval_vals = np.array(eval_vals, float)\n",
    "\n",
    "            # Compute Wasserstein only (JSD optional)\n",
    "            wd = wasserstein_distance(ref_vals, eval_vals)\n",
    "\n",
    "            records.append({\n",
    "                \"Variable\": var,\n",
    "                \"Metric\": metric_name,\n",
    "                \"Distance\": \"Wasserstein\",\n",
    "                \"Value\": wd\n",
    "            })\n",
    "\n",
    "# ========= SUMMARY OUTPUT =========\n",
    "df_results = pd.DataFrame(records)\n",
    "\n",
    "summary = summarize_bootstrap(\n",
    "    df_results[['Variable', 'Metric', 'Value']])\n",
    "summary['Distance'] = 'Wasserstein'\n",
    "summary = summary[['Variable', 'Metric', 'Distance', 'mean', 'std', 'median',\n",
    "                   'IQR_25', 'IQR_75', 'min', 'max', '95%_CI_low', '95%_CI_high']]\n",
    "\n",
    "summary.to_csv(output_csv, index=False)\n",
    "print(f\"\\n✅ Saved bootstrap summary → {output_csv}\")\n",
    "print(summary.head(10))\n"
   ],
   "id": "51726f5cf1c7a85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
